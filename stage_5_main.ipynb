{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stage_5_main.ipynb",
      "provenance": [],
      "mount_file_id": "1AKxFscYYFuiGB4Ls3-HlAhThPWl4ylgt",
      "authorship_tag": "ABX9TyMVLrlfQ/2k+1CW1BxZJfA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhengwu123/Machine_learning_group_project/blob/master/stage_5_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpEznnA_MYXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "13014f7b-2533-451f-a31f-7e58bb6d2a8a"
      },
      "source": [
        "# load pre trained 5  model \n",
        "# please use  the linked I shared to download pre-trained model(200MB)\n",
        "#I am loading from my google drive\n",
        "import tensorflow as tf\n",
        "\n",
        "!unzip \"/content/drive/My Drive/saved_model.zip\" -d \"/content\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/saved_model.zip\n",
            "replace /content/saved_model/lid_model_0.58.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/__MACOSX/saved_model/._lid_model_0.58.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THjyww7DMuVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read all pre-trained model\n",
        "model_console = tf.keras.models.load_model('saved_model/console_model_0.64.h5')\n",
        "model_di = tf.keras.models.load_model('saved_model/di_model_0.72.h5')\n",
        "model_lid = tf.keras.models.load_model('saved_model/lid_model_0.58.h5')\n",
        "model_main = tf.keras.models.load_model('saved_model/main_model_0.62.h5')\n",
        "model_nei = tf.keras.models.load_model('saved_model/nei_model_0.6.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUCbJL-UcZ2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LDs7jgGZnsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "#functions used to read images\n",
        "nrows = 150\n",
        "ncolumns = 150\n",
        "channels = 3  #change to 1 if you want to use grayscale image\n",
        "\n",
        "\n",
        "#A function to read and process the images to an acceptable format for our model\n",
        "def read_and_process_image(list_of_images):\n",
        "    \"\"\"\n",
        "    Returns two arrays: \n",
        "        X is an array of resized images\n",
        "        y is an array of labels\n",
        "    \"\"\"\n",
        "    X = [] # images\n",
        "    y = [] # labels\n",
        "    \n",
        "    for image in list_of_images:\n",
        "        X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows,ncolumns), interpolation=cv2.INTER_CUBIC))  #Read the image\n",
        "        #get the labels\n",
        "        if 'real' in image:\n",
        "            y.append(1)\n",
        "        elif 'fake' in image:\n",
        "          y.append(0)\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We5nkkZUPInr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def test_accuracy(path):\n",
        "  fake_di = [path+'/{}'.format(i) for i in os.listdir(path+\"/\") if 'di' in i]\n",
        "  fake_main = [path+'/{}'.format(i) for i in os.listdir(path+\"/\") if 'main' in i]\n",
        "  fake_nei = [path+'/{}'.format(i) for i in os.listdir(path+\"/\") if 'nei' in i]\n",
        "  fake_lid = [path+'/{}'.format(i) for i in os.listdir(path+\"/\") if 'lid' in i]\n",
        "  fake_console = [path+'/{}'.format(i) for i in os.listdir(path+\"/\") if 'console' in i]\n",
        "  X_di, y_di = read_and_process_image(fake_di)\n",
        "  X_main, y_main = read_and_process_image(fake_main)\n",
        "  X_nei, y_nei = read_and_process_image(fake_nei)\n",
        "  X_lid, y_lid = read_and_process_image(fake_lid)\n",
        "  X_console, y_console = read_and_process_image(fake_console)\n",
        "\n",
        "  X_di = np.array(X_di)\n",
        "  y_di = np.array(y_di)\n",
        "  X_main = np.array(X_main)\n",
        "  y_main = np.array(y_main)\n",
        "  X_nei= np.array(X_nei)\n",
        "  X_lid= np.array(X_lid)\n",
        "  X_console= np.array(X_console)\n",
        "  predict_1 = model_di.predict(X_di)\n",
        "  \n",
        "\n",
        "  c1 = 0\n",
        "  for i in range(len(predict_1)):\n",
        "    if predict_1[i] > 0.5:\n",
        "      c1 = c1 +1\n",
        "  c1 = c1/len(predict_1)\n",
        "\n",
        "  c2 = 0\n",
        "  predict_main = model_main.predict(X_main)\n",
        "\n",
        "  for i in range(len(predict_main)):\n",
        "    if predict_main[i] > 0.5:\n",
        "      c2 = c2 +1\n",
        "  c2 = c2/len(predict_main)\n",
        "  \n",
        "  c3 = 0\n",
        "  predict_nei = model_nei.predict(X_nei)\n",
        "  for i in range(len(predict_nei)):\n",
        "    if predict_nei[i] > 0.5:\n",
        "      c3 = c3 + 1\n",
        "  c3 = c3/len(predict_nei)\n",
        "\n",
        "  c4 = 0\n",
        "  predict_lid = model_lid.predict(X_lid)\n",
        "  for i in range(len(predict_lid)):\n",
        "    if predict_lid[i] > 0.5:\n",
        "      c4 = c4 + 1\n",
        "  c4 = c4/len(predict_lid)\n",
        "\n",
        "  predict_console = model_console.predict(X_console)\n",
        "  c5 = 0\n",
        "  for i in range(len(predict_console)):\n",
        "    if predict_console[i] > 0.5:\n",
        "      c5 = c5 + 1\n",
        "  c5 = c5/len(predict_console)\n",
        "\n",
        "\n",
        "  count = c3* ( 0.72*c1 + c2 *0.62 + c3 * 0.6 + c4*0.58 + c5*0.64 ) /316\n",
        "  if count == 0:\n",
        "    return \"real\"\n",
        "  else:\n",
        "    return \"fake\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLYkCqUoaYCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cc9af60f-ecb9-4894-9b72-3039ec9f9d9e"
      },
      "source": [
        "#unzip testing images\n",
        "#!rm -rf test_data/\n",
        "!unzip test_data.zip"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test_data.zip\n",
            "replace test_data/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnMUM0boSgCp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "33fa562d-4bc8-477b-f304-1a3a2b820c2d"
      },
      "source": [
        "#start testing....\n",
        "print(\"testing data/1-----------\",test_accuracy(\"test_data/1\"))\n",
        "print(\"testing data/2-----------\",test_accuracy(\"test_data/2\"))\n",
        "print(\"testing data/3-----------\",test_accuracy(\"test_data/3\"))\n",
        "print(\"testing data/4-----------\",test_accuracy(\"test_data/4\"))\n",
        "print(\"testing data/5-----------\",test_accuracy(\"test_data/5\"))\n",
        "print(\"testing data/6-----------\",test_accuracy(\"test_data/6\"))\n",
        "print(\"testing data/7-----------\",test_accuracy(\"test_data/7\"))\n",
        "print(\"testing data/8-----------\",test_accuracy(\"test_data/8\"))\n",
        "print(\"testing data/9-----------\",test_accuracy(\"test_data/9\"))\n",
        "print(\"testing data/10-----------\",test_accuracy(\"test_data/10\"))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing data/1----------- real\n",
            "testing data/2----------- real\n",
            "testing data/3----------- real\n",
            "testing data/4----------- fake\n",
            "testing data/5----------- real\n",
            "testing data/6----------- fake\n",
            "testing data/7----------- real\n",
            "testing data/8----------- fake\n",
            "testing data/9----------- real\n",
            "testing data/10----------- fake\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}